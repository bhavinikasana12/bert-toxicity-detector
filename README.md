# ğŸ›¡ï¸ BERT Toxicity Classifier  

This project fine-tunes **BERT** to detect toxic comments. It classifies text as **toxic** or **non-toxic** using Natural Language Processing (NLP).  

## Features  
Fine-tuned **BERT-base-uncased** model  
Detects **toxic language** in text  
Trained on **Jigsaw Unintended Bias in Toxicity Classification** dataset  

## ğŸš€ Quick Start  

### **1ï¸âƒ£ Clone the Repository**  
```bash
git clone https://github.com/yourusername/bert-toxicity-detector.git
cd bert-toxicity-detector
